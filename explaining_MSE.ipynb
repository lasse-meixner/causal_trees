{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining the loss of a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory, SHAP values can be used to explain anything about a machine learning model that can be formulated as the \"value of the game\" $v(S)$ for a coalition $S$.\n",
    "\n",
    "Typically, when people talk about using shap explanations on a machine learning model, they refer to explaining the contribution to the prediction output.\n",
    "\n",
    "There are however many alternative applications in the machine learning literature, including for example **feature selection**, where $v(S)$ is the model performance, **data valuation**, where $v(S)$ is the goodness of fit on test data, or **monitoring**, where $v(S)$ is the model loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will look closer at how shap values can be used to explain the loss of a model. \n",
    "\n",
    "In particular, I will be interested in explaining the contribution of each feature/covariate to the MSE at the leaf level of a tree ensemble regression model. This will allow to characterize the hetereogeneity of CATEs within the leafs of the tree ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Existing approaches and shortcomings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the existing implementation of [treeSHAP](https://shap-lrjball.readthedocs.io/en/latest/generated/shap.TreeExplainer.html) in the mainstream package for shap values, `shap`, there is the possibility to compute the `log_loss` of binary classification models, but not more general loss functions. (Note that when computing any loss, one has to pass the label to the shap explainer as well.)\n",
    "\n",
    "It also mentions that it is possible to pass \"the name of a supported prediction method on the model object\" for which the shap values will then be computed. Besides raw output and probabilities for classification, however, there are no default methods to get the MSE.\n",
    "\n",
    "Instead of having to modify the `shap` package, there might be an easy way by creating a wrapper class for our RandomForestRegressor that exhibits a method that returns the leaf node MSE for any observation.\n",
    "\n",
    "A complication is that this \"custom\" model output shap explanation is only supported for `feature_perturbation=\"interventional`, as opposed to the default `feature_perturbation=\"tree_path_dependent\"`, which uses the background training samples that went down each tree path to compute \"observational conditional expectations\" from which to sample \"inactive\" features. \n",
    "\n",
    "The `interventional` method requires to pass a background dataset (with regards to which runtime scales linearly), and the documentation suggests to use anywhere from 100 to 1000 random background samples. It claims that the `interventional` approach *\"breaks the dependencies between features according to the rules dictated by causal inference [(Janzing et al. 2019)](https://proceedings.neurips.cc/paper/2019/file/2172fde49301047270b2897085e4319d-Paper.pdf)\"*. It is not yet clear to me how this can be done without integrating any causal knowledge about our Xs into the model - the formulation is probably unfortunate at best. \n",
    "\n",
    "The most convincing way I have seen this done is as demonstrated by (Heskes, Bucur, Sijben and Claassen 2020) from Radboud University, which suggest and demonstrate to use Pearls do-calculus to compute interventional conditional distributions, and so naturally asks for a DAG.\n",
    "\n",
    "In any case, this is important to be aware of. I think one can make a case for being interested in the interpretation that the `interventional` approach, but if not, then there is no way around touching the `shap` package (which might be very difficult)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea behind explaining loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\Pi$ denote the partition of a fit regression tree, and $l(x, \\Pi)$ the leaf node that $x$ falls into under partition $\\Pi$.\n",
    "\n",
    "For each input vector $x_i$, a standard fitted decision tree regressor provides output \n",
    "$$\n",
    "f(x_i) = \\frac{1}{\\#\\{k \\in l(x_i, \\Pi)\\}} \\sum_{k \\in l(x_i, \\Pi)}\\bar{Y_k}\n",
    "$$\n",
    "\n",
    "Similarly, for each input vector $x$, we can consider the loss at each input vector:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{loss}(x_i) &= (y-f(x_i))^2 \\\\\n",
    "&= (y - \\frac{1}{\\#\\{k \\in l(x_i, \\Pi)\\}} \\sum_{k \\in l(x_i, \\Pi)}\\bar{Y_k})^2\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The overall MSE loss of the data is just the average of the squared error at each input vector:\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n \\text{loss}(x_i)\n",
    "$$\n",
    "\n",
    "These are feasible to compute for any input vector $x_i$ and any partition $\\Pi$ since we know the outcome $y_i$ for each collection of covariates in an input vector $x_i$. This will not be the case for CATE in causal trees, for the standard \"fundamental problem of causal inference\". In that case we will resort to corresponding estimators from our estimation data (Athey & Wager, PNAS 2016).\n",
    "\n",
    "Let's now see how we can use shap to explain such loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is shap contribution to loss not a simple function of contribution to prediction?\n",
    "\n",
    "One might wonder why the contribution of a particular feature value to the loss is not immediately understood by looking at the contribution of that feature value to the prediction, since the \"role\" of the feature only plays into f(x) in the squared error formula.\n",
    "The reason is that it is a nonlinear transformation, which means, by the linearity property of the Shapley value solution concept\n",
    "$$\n",
    "\\phi(N,v+w) = \\phi(N,v) + \\phi(N,w) \\quad \\text{for any games} (N,v) \\text{ and } (N,w) \\quad\\quad \\text{(see shap\\_intro.ipynb)}\n",
    "$$\n",
    "that the contribution to loss cannot be easily disentangled from the distribution to prediction:\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{Squared error}(x_i) &= (y_i-\\hat{f}(x_i))^2 \\\\\n",
    "&= y_i^2 - 2y_i\\hat{f}(x_i) + \\hat{f}(x_i)^2 \\\\\n",
    "\\end{align*}\n",
    "\n",
    "So whilst scalar shifts or multiplications of the prediction $\\hat{f}(x_i)$ is a simple linear transformation of the known contribution to the prediction $\\phi(N,\\hat{f}(x_i))$ we get for free, the contribution to the squared error is not known and has to be computed on its own:\n",
    "\n",
    "\\begin{align*}\n",
    "\\phi(N, (y_i-\\hat{f}(x_i))^2) &= \\phi(N, y_i^2 - 2y_i\\hat{f}(x_i) + \\hat{f}(x_i)^2) \\\\\n",
    "&= y_i^2 - 2y_i\\phi(N, \\hat{f}(x_i)) + \\phi(N, \\hat{f}(x_i)^2)\n",
    "\\end{align*}\n",
    "\n",
    "**In other words, we know the contribution to the squared error of an observation as soon as we know the outcome, the contribution to the prediction, and to the prediction squared.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a custom tree regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now turn to a demonstration of how we can use shap to explain squared loss using the `shap` package. I will begin with an exposition on a single tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Load the Diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# create joint dataframe\n",
    "df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
    "df['target'] = diabetes.target\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  target  \n",
       "0 -0.002592  0.019907 -0.017646   151.0  \n",
       "1 -0.039493 -0.068332 -0.092204    75.0  \n",
       "2 -0.002592  0.002861 -0.025930   141.0  \n",
       "3  0.034309  0.022688 -0.009362   206.0  \n",
       "4 -0.002592 -0.031988 -0.046641   135.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now define a custom tree regressor class that extends the standard sklearn model for a simple method that computes the squared loss for each observation, and can be used similar to a `.predict()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/lasse/Library/Mobile Documents/com~apple~CloudDocs/Oxford MPhil/Thesis/Shap/code/explaining_MSE.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# define a new estimator with our new custom loss\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCustomDecisionTree\u001b[39;00m(DecisionTreeRegressor):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X20sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         ccp_alpha\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X20sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     ):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X20sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m             criterion\u001b[39m=\u001b[39mcriterion,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X20sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m             splitter\u001b[39m=\u001b[39msplitter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X20sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m             ccp_alpha\u001b[39m=\u001b[39mccp_alpha,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X20sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         ) \u001b[39m# setting them all this way respects the scikit-learn demanded init structure\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "# define a new estimator with our new custom loss\n",
    "\n",
    "class CustomDecisionTree(DecisionTreeRegressor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        criterion=\"squared_error\",\n",
    "        splitter=\"best\",\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        min_weight_fraction_leaf=0.0,\n",
    "        max_features=None,\n",
    "        random_state=None,\n",
    "        max_leaf_nodes=None,\n",
    "        min_impurity_decrease=0.0,\n",
    "        ccp_alpha=0.0,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            criterion=criterion,\n",
    "            splitter=splitter,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_features=max_features,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            random_state=random_state,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            ccp_alpha=ccp_alpha,\n",
    "        ) # setting them all this way respects the scikit-learn demanded init structure\n",
    "    \n",
    "    def leaf_mean_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        Computes the squared loss between the outcome and the mean value of the leaf node to which x traverses through the partition.\n",
    "\n",
    "        Parameters:\n",
    "            X (array-like or sparse matrix): Input samples.\n",
    "\n",
    "        Returns:\n",
    "            array-like: Array of squared errors between the predicted values and the mean value of the leaf nodes.\n",
    "        \"\"\"\n",
    "        # check that tree is fitted\n",
    "        assert self.tree_ is not None\n",
    "\n",
    "        # return squared loss\n",
    "        sq_loss = (y - self.predict(X))**2\n",
    "        \n",
    "        return sq_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to train our custom tree on the diabetes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    estimator=CustomDecisionTree(),\n",
    "    param_grid={'max_depth': np.arange(2, 10)},\n",
    "    cv = 4)\n",
    "grid.fit(df.drop(\"target\",axis = 1), df.target)\n",
    "\n",
    "# get the best estimator\n",
    "best_estimator = grid.best_estimator_\n",
    "\n",
    "# get the best parameters\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the loss for each observation\n",
    "loss = best_estimator.leaf_mean_loss(df.drop(\"target\",axis = 1), df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3360.050096675736\n",
      "3360.050096675736\n"
     ]
    }
   ],
   "source": [
    "# lets check this adds up to the MSE\n",
    "print(np.sum(loss) / len(loss))\n",
    "print(mean_squared_error(df.target, best_estimator.predict(df.drop(\"target\",axis = 1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having now defined a custom loss function, we should be able to use default shap code to explain the loss of our model using our model method name using the `model_output = 'leaf_mean_loss'` argument, as explained in their [documentation](https://shap-lrjball.readthedocs.io/en/latest/generated/shapTreeExplainer.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(NOTE: Deprecations in numpy 1.23 -> 1.24 have caused some issues in the shap package, see [here](https://github.com/shap/shap/issues/2911). It is best to go with numpy 1.23 and shap 0.42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP for predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first compute the standard \"prediction\" shap explanation on our diabetes data using our custom tree regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42.1\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "print(shap.__version__)\n",
    "\n",
    "# compute SHAP values\n",
    "explainer = shap.TreeExplainer(best_estimator)\n",
    "prediction_shap_values = explainer(df.drop(\"target\",axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make beeswarm plot of shap values\n",
    "shap.plots.beeswarm(prediction_shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that only BMI and s5 have any influence on the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHAP for loss using \"model method name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_dependence = \"independent\" has been renamed to feature_perturbation = \"interventional\"! See GitHub issue #882.\n"
     ]
    },
    {
     "ename": "ExplainerError",
     "evalue": "Currently TreeExplainer can only handle models with categorical splits when feature_perturbation=\"tree_path_dependent\" and no background data is passed. Please try again using shap.TreeExplainer(model, feature_perturbation=\"tree_path_dependent\").",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/eda/lib/python3.10/site-packages/shap/explainers/_tree.py:198\u001b[0m, in \u001b[0;36mTree.__init__\u001b[0;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, **deprecated_options)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpected_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\u001b[39m.\u001b[39mmean(\u001b[39m0\u001b[39m)\n\u001b[1;32m    199\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/eda/lib/python3.10/site-packages/shap/explainers/_tree.py:1264\u001b[0m, in \u001b[0;36mTreeEnsemble.predict\u001b[0;34m(self, X, y, output, tree_limit)\u001b[0m\n\u001b[1;32m   1263\u001b[0m     \u001b[39massert\u001b[39;00m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(y), \u001b[39m\"\u001b[39m\u001b[39mThe number of labels (\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m) does not match the number of samples to explain (\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m)!\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39m(y), X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m-> 1264\u001b[0m transform \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_transform()\n\u001b[1;32m   1265\u001b[0m assert_import(\u001b[39m\"\u001b[39m\u001b[39mcext\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/eda/lib/python3.10/site-packages/shap/explainers/_tree.py:1217\u001b[0m, in \u001b[0;36mTreeEnsemble.get_transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     emsg \u001b[39m=\u001b[39m (\n\u001b[1;32m   1213\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized model_output parameter value: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_output)\u001b[39m}\u001b[39;00m\u001b[39m! \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIf `model.\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_output)\u001b[39m}\u001b[39;00m\u001b[39m` is a valid function, open a Github issue to ask \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthat this method be supported. If you want \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpredict_proba\u001b[39m\u001b[39m'\u001b[39m\u001b[39m just use \u001b[39m\u001b[39m'\u001b[39m\u001b[39mprobability\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for now.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1216\u001b[0m     )\n\u001b[0;32m-> 1217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(emsg)\n\u001b[1;32m   1219\u001b[0m \u001b[39mreturn\u001b[39;00m transform\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized model_output parameter value: leaf_mean_loss! If `model.leaf_mean_loss` is a valid function, open a Github issue to ask that this method be supported. If you want 'predict_proba' just use 'probability' for now.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mExplainerError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/lasse/Library/Mobile Documents/com~apple~CloudDocs/Oxford MPhil/Thesis/Shap/code/explaining_MSE.ipynb Cell 29\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# now we specify our custom loss function\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m loss_explainer \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39;49mTreeExplainer(best_estimator, df\u001b[39m.\u001b[39;49mdrop(\u001b[39m\"\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m\"\u001b[39;49m,axis \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m), feature_dependence\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mindependent\u001b[39;49m\u001b[39m\"\u001b[39;49m, model_output\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mleaf_mean_loss\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m loss_shap_values \u001b[39m=\u001b[39m loss_explainer\u001b[39m.\u001b[39mshap_values(df\u001b[39m.\u001b[39mdrop(\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m,axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m), df\u001b[39m.\u001b[39mtarget)\n",
      "File \u001b[0;32m~/miniconda3/envs/eda/lib/python3.10/site-packages/shap/explainers/_tree.py:200\u001b[0m, in \u001b[0;36mTree.__init__\u001b[0;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, **deprecated_options)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpected_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\u001b[39m.\u001b[39mmean(\u001b[39m0\u001b[39m)\n\u001b[1;32m    199\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mraise\u001b[39;00m ExplainerError(\u001b[39m\"\u001b[39m\u001b[39mCurrently TreeExplainer can only handle models with categorical splits when \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[1;32m    201\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mfeature_perturbation=\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mtree_path_dependent\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m and no background data is passed. Please try again using \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[1;32m    202\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mshap.TreeExplainer(model, feature_perturbation=\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mtree_path_dependent\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpected_value, \u001b[39m'\u001b[39m\u001b[39m__len__\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpected_value) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpected_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpected_value[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mExplainerError\u001b[0m: Currently TreeExplainer can only handle models with categorical splits when feature_perturbation=\"tree_path_dependent\" and no background data is passed. Please try again using shap.TreeExplainer(model, feature_perturbation=\"tree_path_dependent\")."
     ]
    }
   ],
   "source": [
    "# now we specify our custom loss function\n",
    "\n",
    "loss_explainer = shap.TreeExplainer(best_estimator, df.drop(\"target\",axis = 1), feature_dependence=\"independent\", model_output=\"leaf_mean_loss\")\n",
    "loss_shap_values = loss_explainer.shap_values(df.drop(\"target\",axis = 1), df.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is happening here?**\n",
    "\n",
    "Unrecognized parameter value: leaf_mean_loss... Even though it is a well defined model method name. So it seems that the documentation is a bit misleading here.\n",
    "\n",
    "I checked the source code, and found out that the model method name is actually simply not implemented.\n",
    "\n",
    "Because the output predictions are computed using a tree in the C-extension, these arguments are not actually passed to the python model, so one has to translate this for adapter to the C-extension.\n",
    "\n",
    "I opened a [issue on github](https://github.com/shap/shap/issues/3420) to ask how this could be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *a cheap workaround (just for my memory...)?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Update]: Reading the [shap source code](https://github.com/shap/shap/blob/d534ef30e33d21672b22addee245a3f3e6dd23e0/shap/explainers/_tree.py#L1238-L1273) I tried some cheap workarounds here, but they didn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the source-code, I discovered that this adapter is pretty messy. Glancing over, it seems that if you pass \"log_loss\" and the criterion is \"squared_error\", the transform passed to the c-extension is \"squared_loss\". Would this give you the MSE?\n",
    "\n",
    "(from the source)\n",
    "```python\n",
    "    elif self.model_output == \"log_loss\":\n",
    "        if self.objective == \"squared_error\":\n",
    "            transform = \"squared_loss\"\n",
    "```\n",
    "\n",
    "Let's see if this actually works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "model_output = \"log_loss\" is not yet supported when model.objective = \"None\"!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/lasse/Library/Mobile Documents/com~apple~CloudDocs/Oxford MPhil/Thesis/Shap/code/explaining_MSE.ipynb Cell 33\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m loss_explainer \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39mTreeExplainer(best_estimator, df\u001b[39m.\u001b[39mdrop(\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m,axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m), model_output\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlog_loss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m loss_shap_values \u001b[39m=\u001b[39m loss_explainer(X \u001b[39m=\u001b[39;49m df\u001b[39m.\u001b[39;49mdrop(\u001b[39m\"\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m\"\u001b[39;49m,axis \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m), y\u001b[39m=\u001b[39;49mdf\u001b[39m.\u001b[39;49mtarget)\n",
      "File \u001b[0;32m~/miniconda3/envs/eda/lib/python3.10/site-packages/shap/explainers/_tree.py:233\u001b[0m, in \u001b[0;36mTree.__call__\u001b[0;34m(self, X, y, interactions, check_additivity)\u001b[0m\n\u001b[1;32m    230\u001b[0m     feature_names \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata_feature_names\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m interactions:\n\u001b[0;32m--> 233\u001b[0m     v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshap_values(X, y\u001b[39m=\u001b[39;49my, from_call\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, check_additivity\u001b[39m=\u001b[39;49mcheck_additivity, approximate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapproximate)\n\u001b[1;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(v) \u001b[39mis\u001b[39;00m \u001b[39mlist\u001b[39m:\n\u001b[1;32m    235\u001b[0m         v \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(v, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# put outputs at the end\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/eda/lib/python3.10/site-packages/shap/explainers/_tree.py:419\u001b[0m, in \u001b[0;36mTree.shap_values\u001b[0;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m    416\u001b[0m X, y, X_missing, flat_output, tree_limit, check_additivity \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_inputs(\n\u001b[1;32m    417\u001b[0m     X, y, tree_limit, check_additivity\n\u001b[1;32m    418\u001b[0m )\n\u001b[0;32m--> 419\u001b[0m transform \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mget_transform()\n\u001b[1;32m    421\u001b[0m \u001b[39m# run the core algorithm using the C extension\u001b[39;00m\n\u001b[1;32m    422\u001b[0m assert_import(\u001b[39m\"\u001b[39m\u001b[39mcext\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/eda/lib/python3.10/site-packages/shap/explainers/_tree.py:1210\u001b[0m, in \u001b[0;36mTreeEnsemble.get_transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1206\u001b[0m         emsg \u001b[39m=\u001b[39m (\n\u001b[1;32m   1207\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmodel_output = \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mlog_loss\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m is not yet supported when model.objective = \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1208\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective\u001b[39m}\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1209\u001b[0m         )\n\u001b[0;32m-> 1210\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(emsg)\n\u001b[1;32m   1211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m     emsg \u001b[39m=\u001b[39m (\n\u001b[1;32m   1213\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized model_output parameter value: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_output)\u001b[39m}\u001b[39;00m\u001b[39m! \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIf `model.\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_output)\u001b[39m}\u001b[39;00m\u001b[39m` is a valid function, open a Github issue to ask \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthat this method be supported. If you want \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpredict_proba\u001b[39m\u001b[39m'\u001b[39m\u001b[39m just use \u001b[39m\u001b[39m'\u001b[39m\u001b[39mprobability\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for now.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1216\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: model_output = \"log_loss\" is not yet supported when model.objective = \"None\"!"
     ]
    }
   ],
   "source": [
    "loss_explainer = shap.TreeExplainer(best_estimator, df.drop(\"target\",axis = 1), model_output=\"log_loss\")\n",
    "loss_shap_values = loss_explainer(X = df.drop(\"target\",axis = 1), y=df.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason model.objective is not set to our criterion (squared_error, see below)... Is this just because we are a custom model that the shap explainer does not know about?\n",
    "\n",
    "(again, from .tree source)\n",
    "```python\n",
    "[...]\n",
    "elif safe_isinstance(\n",
    "    model,\n",
    "    [\n",
    "        \"sklearn.tree.DecisionTreeRegressor\",\n",
    "        \"sklearn.tree.tree.DecisionTreeRegressor\",\n",
    "        \"econml.grf._base_grftree.GRFTree\",\n",
    "    ],\n",
    "):\n",
    "    self.internal_dtype = model.tree_.value.dtype.type\n",
    "    self.input_dtype = np.float32\n",
    "    self.trees = [SingleTree(model.tree_, data=data, data_missing=data_missing)]\n",
    "    self.objective = objective_name_map.get(model.criterion, None)\n",
    "    self.tree_output = \"raw_value\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.CustomDecisionTree"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(best_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'squared_error'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator.criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so lets go back to a basic tree and see if we can get it to work using the log_loss argument to get the squared loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train standard decision tree\n",
    "\n",
    "gscv = GridSearchCV(\n",
    "    estimator=DecisionTreeRegressor(),\n",
    "    param_grid={'max_depth': np.arange(2, 10)},\n",
    "    cv = 4)\n",
    "\n",
    "gscv.fit(df.drop(\"target\",axis = 1), df.target)\n",
    "\n",
    "best_tree = gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_dependence = \"independent\" has been renamed to feature_perturbation = \"interventional\"! See GitHub issue #882.\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "model_output = \"log_loss\" is not yet supported when model.objective = \"None\"!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/lasse/Library/Mobile Documents/com~apple~CloudDocs/Oxford MPhil/Thesis/Shap/code/explaining_MSE.ipynb Cell 39\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# get treeshap explainer\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#Y103sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tree_explainer \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39mTreeExplainer(best_tree, df\u001b[39m.\u001b[39mdrop(\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m,axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m), feature_dependence\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mindependent\u001b[39m\u001b[39m\"\u001b[39m, model_output\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlog_loss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lasse/Library/Mobile%20Documents/com~apple~CloudDocs/Oxford%20MPhil/Thesis/Shap/code/explaining_MSE.ipynb#Y103sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m shape_values \u001b[39m=\u001b[39m tree_explainer\u001b[39m.\u001b[39;49mshap_values(df\u001b[39m.\u001b[39;49mdrop(\u001b[39m\"\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m\"\u001b[39;49m,axis \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m), df\u001b[39m.\u001b[39;49mtarget)\n",
      "File \u001b[0;32m~/miniconda3/envs/eda/lib/python3.10/site-packages/shap/explainers/_tree.py:419\u001b[0m, in \u001b[0;36mTree.shap_values\u001b[0;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m    416\u001b[0m X, y, X_missing, flat_output, tree_limit, check_additivity \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_inputs(\n\u001b[1;32m    417\u001b[0m     X, y, tree_limit, check_additivity\n\u001b[1;32m    418\u001b[0m )\n\u001b[0;32m--> 419\u001b[0m transform \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mget_transform()\n\u001b[1;32m    421\u001b[0m \u001b[39m# run the core algorithm using the C extension\u001b[39;00m\n\u001b[1;32m    422\u001b[0m assert_import(\u001b[39m\"\u001b[39m\u001b[39mcext\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/eda/lib/python3.10/site-packages/shap/explainers/_tree.py:1210\u001b[0m, in \u001b[0;36mTreeEnsemble.get_transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1206\u001b[0m         emsg \u001b[39m=\u001b[39m (\n\u001b[1;32m   1207\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmodel_output = \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mlog_loss\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m is not yet supported when model.objective = \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1208\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective\u001b[39m}\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1209\u001b[0m         )\n\u001b[0;32m-> 1210\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(emsg)\n\u001b[1;32m   1211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1212\u001b[0m     emsg \u001b[39m=\u001b[39m (\n\u001b[1;32m   1213\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized model_output parameter value: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_output)\u001b[39m}\u001b[39;00m\u001b[39m! \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIf `model.\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_output)\u001b[39m}\u001b[39;00m\u001b[39m` is a valid function, open a Github issue to ask \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthat this method be supported. If you want \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpredict_proba\u001b[39m\u001b[39m'\u001b[39m\u001b[39m just use \u001b[39m\u001b[39m'\u001b[39m\u001b[39mprobability\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for now.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1216\u001b[0m     )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: model_output = \"log_loss\" is not yet supported when model.objective = \"None\"!"
     ]
    }
   ],
   "source": [
    "# get treeshap explainer\n",
    "\n",
    "tree_explainer = shap.TreeExplainer(best_tree, df.drop(\"target\",axis = 1), feature_dependence=\"independent\", model_output=\"log_loss\")\n",
    "shape_values = tree_explainer.shap_values(df.drop(\"target\",axis = 1), df.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No... It checks that we are not a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with clasisfication\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# define binary y as target over target.mean()\n",
    "\n",
    "df['target_binary'] = (df.target > df.target.mean()).astype(int)\n",
    "\n",
    "# train classifier\n",
    "\n",
    "gscv = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    param_grid={'max_depth': np.arange(2, 10)},\n",
    "    cv = 4)\n",
    "\n",
    "gscv.fit(df.drop([\"target\", \"target_binary\"],axis = 1), df.target_binary)\n",
    "\n",
    "best_clf = gscv.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_dependence = \"independent\" has been renamed to feature_perturbation = \"interventional\"! See GitHub issue #882.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.        ,  0.        , -0.10934881, ...,  0.        ,\n",
       "         -0.11823457,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.11022653, ...,  0.        ,\n",
       "          0.12788771,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.10934881, ...,  0.        ,\n",
       "         -0.11823457,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.11022653, ...,  0.        ,\n",
       "          0.12788771,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.07238968, ...,  0.        ,\n",
       "          0.0747089 ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.11022653, ...,  0.        ,\n",
       "          0.12788771,  0.        ]]),\n",
       " array([[ 0.        ,  0.        ,  0.11646402, ...,  0.        ,\n",
       "          0.12153013,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.09942289, ...,  0.        ,\n",
       "         -0.11848999,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.11646402, ...,  0.        ,\n",
       "          0.12153013,  0.        ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        , -0.09942289, ...,  0.        ,\n",
       "         -0.11848999,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.06527447, ...,  0.        ,\n",
       "         -0.07141334,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.09942289, ...,  0.        ,\n",
       "         -0.11848999,  0.        ]])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get ACTUAL log loss by using a classifier\n",
    "\n",
    "explainer = shap.TreeExplainer(best_clf, df.drop([\"target\", \"target_binary\"],axis = 1), feature_dependence=\"independent\", model_output=\"log_loss\")\n",
    "explainer.shap_values(df.drop([\"target\", \"target_binary\"],axis = 1), df.target_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it might be that this workaround could nevertheless work if we only play around with how the instance attributes are set in the shap implementation of the tree within the shap explainer, if it is true that the underlying C-extension is set up to compute the MSE when the criterion is \"squared_error\" and the model_output is \"log_loss\"... In any case the the shap code needs to be fixed or the documentation adjusted...\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_trees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
